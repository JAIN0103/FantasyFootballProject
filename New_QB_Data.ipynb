{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "New_QB_Data",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic7uO2_k4J1d"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "pd.set_option('display.max_rows', 500)\n",
        "pd.set_option('display.max_columns', 500)\n",
        "pd.set_option('display.width', 150)\n",
        "df = pd.read_excel('2013-2019_QB_Data.xlsx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGeI-XR66My5"
      },
      "source": [
        "df = df.drop(['Player'], axis=1)\n",
        "df = df.iloc[np.random.permutation(len(df))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXcbAXfw4txv"
      },
      "source": [
        "train_df = df[:110]\n",
        "test_df = df[110:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDwubh-p87oC",
        "outputId": "dacc58c1-8f64-4446-ce75-1dcb9b6f620d"
      },
      "source": [
        "train_df['7_x'] = train_df['7_x'].replace(',','',regex=True)\n",
        "train_df['4_y'] = train_df['4_y'].replace(',','',regex=True)\n",
        "test_df['7_x'] = test_df['7_x'].replace(',','',regex=True)\n",
        "test_df['4_y'] = test_df['4_y'].replace(',','',regex=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OgTTLRPo7_Zj"
      },
      "source": [
        "train_df = train_df.astype(float)\n",
        "test_df = test_df.astype(float)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tTFfxGuz4t7X"
      },
      "source": [
        "train_average_points = train_df.pop('Following_Year_PPG')\n",
        "\n",
        "test_average_points = test_df.pop('Following_Year_PPG')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fCpPHyGH4uAd"
      },
      "source": [
        "import tensorflow as tf\n",
        "dataset = tf.data.Dataset.from_tensor_slices((train_df.values, train_average_points.values))\n",
        "train_dataset = dataset.shuffle(len(df)).batch(1)\n",
        "\n",
        "dataset = tf.data.Dataset.from_tensor_slices((test_df.values, test_average_points.values))\n",
        "test_dataset = dataset.shuffle(len(df)).batch(1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pbxevEQC4uF4"
      },
      "source": [
        "from tensorflow import keras\n",
        "def get_compiled_model():\n",
        "  model = tf.keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape=(18,)),\n",
        "    keras.layers.Dense(20, activation='relu'),\n",
        "\t  keras.layers.Dense(20, activation='relu'),\n",
        "    tf.keras.layers.GaussianNoise(0.1),\n",
        "    keras.layers.Dense(1)\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam',\n",
        "                loss='mse',\n",
        "                metrics=['mae'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJLv17YA4uLP",
        "outputId": "bc4b958e-897d-4957-ce27-3c5cc3cbd056"
      },
      "source": [
        "model = get_compiled_model()\n",
        "model.fit(train_dataset, epochs=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 1s 1ms/step - loss: 5753.3486 - mae: 45.0350\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 219.8329 - mae: 11.5132\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 131.2968 - mae: 8.5180\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 122.6162 - mae: 8.7978\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 96.1822 - mae: 7.7976\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 82.1164 - mae: 7.1960\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 88.0089 - mae: 7.6221\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 77.2962 - mae: 7.0571\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 64.7166 - mae: 6.4575\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 74.6172 - mae: 7.1932\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 74.6738 - mae: 6.8959\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 57.3971 - mae: 6.0713\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 44.3484 - mae: 5.3031\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 71.6232 - mae: 6.7284\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 121.2992 - mae: 8.1770\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 65.8502 - mae: 6.4464\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 53.6801 - mae: 5.7828\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 86.6732 - mae: 7.3521\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.3818 - mae: 5.9925\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.8913 - mae: 5.3505\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 63.6123 - mae: 6.2016\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 73.2582 - mae: 6.7342\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 75.2177 - mae: 6.7175\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.1260 - mae: 4.6586\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 55.8392 - mae: 5.8600\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 43.1900 - mae: 5.1209\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 43.1340 - mae: 4.9539\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 56.1744 - mae: 5.6817\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.4138 - mae: 5.4443\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 137.0076 - mae: 8.7611\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 94.0717 - mae: 6.9051\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 35.6304 - mae: 4.6874\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 110.5178 - mae: 8.0795\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.4249 - mae: 5.3601\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.9555 - mae: 5.7819\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 155.2363 - mae: 9.2830\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.2219 - mae: 6.3022\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 71.4353 - mae: 6.2413\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 75.4237 - mae: 6.8034\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.8486 - mae: 5.6035\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.7035 - mae: 4.4415\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 59.9800 - mae: 6.1751\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 63.6903 - mae: 5.9027\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 57.0599 - mae: 6.0934\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 54.5263 - mae: 5.9105\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.9853 - mae: 4.8684\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 126.1871 - mae: 8.5020\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 118.6178 - mae: 8.4259\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 87.3981 - mae: 6.9828\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 61.7694 - mae: 6.1549\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fb59f9bb790>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BOJiNAcU4uQt",
        "outputId": "8ed17feb-1a26-4751-a3fe-844ec28fe671"
      },
      "source": [
        "test_loss, test_acc = model.evaluate(test_df, test_average_points)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 97ms/step - loss: 42.0605 - mae: 4.8782\n",
            "Test accuracy: 4.878199100494385\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "IdTAKybuQoxL",
        "outputId": "7c3f216d-f096-410c-f133-af1132854fec"
      },
      "source": [
        "while True:\n",
        "  model = get_compiled_model()\n",
        "  model.fit(train_dataset, epochs=50)\n",
        "  test_loss, test_acc = model.evaluate(test_df, test_average_points)\n",
        "  print('Test accuracy:', test_acc)\n",
        "  if test_acc < 2:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "110/110 [==============================] - 1s 1ms/step - loss: 740.7160 - mae: 17.9687\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 95.6011 - mae: 7.6052\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 120.2952 - mae: 8.7221\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 98.0934 - mae: 7.8268\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 73.3328 - mae: 6.9501\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.7533 - mae: 4.8649\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 59.8795 - mae: 5.9229\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 52.9839 - mae: 5.4277\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 49.4986 - mae: 5.5270\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 50.0581 - mae: 5.5798\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 61.8050 - mae: 6.1148\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.6745 - mae: 4.7607\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 47.6134 - mae: 5.6449\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.1373 - mae: 5.4659\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 85.9702 - mae: 7.5042\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.2522 - mae: 4.6531\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 48.4963 - mae: 5.3665\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 157.6463 - mae: 9.4074\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 43.2619 - mae: 5.1626\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.9288 - mae: 4.6996\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.7112 - mae: 4.4008\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 67.1089 - mae: 6.5520\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 88.2516 - mae: 7.2021\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 63.6082 - mae: 6.1480\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.4284 - mae: 4.7428\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.6399 - mae: 4.7650\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.1241 - mae: 4.9924\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 67.3913 - mae: 6.2873\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.2884 - mae: 5.7791\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 68.5738 - mae: 6.4426\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 82.5273 - mae: 7.2284\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 66.2197 - mae: 6.3173\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.7427 - mae: 4.6654\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 27.7431 - mae: 4.0641\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 51.4210 - mae: 5.5721\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.6171 - mae: 5.6211\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 38.2155 - mae: 4.7721\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.9597 - mae: 5.4719\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 44.9732 - mae: 5.0358\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.4480 - mae: 4.6828\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 38.9277 - mae: 4.6899\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.0015 - mae: 5.3955\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 40.8005 - mae: 4.8704\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 60.4329 - mae: 6.1778\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.8707 - mae: 5.1419\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.5578 - mae: 5.2493\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 41.2615 - mae: 5.0363\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.2750 - mae: 4.1342\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.7512 - mae: 5.2172\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 34.2466 - mae: 4.6126\n",
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb599acf950> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 110ms/step - loss: 27.6152 - mae: 3.8298\n",
            "Test accuracy: 3.8298099040985107\n",
            "Epoch 1/50\n",
            "110/110 [==============================] - 1s 1ms/step - loss: 93075.8984 - mae: 168.2311\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 51.4942 - mae: 5.4610\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 41.9788 - mae: 5.1544\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.6298 - mae: 5.1041\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.6752 - mae: 5.1387\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 35.5078 - mae: 4.6869\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.9302 - mae: 4.8236\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.7918 - mae: 4.4101\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 34.1760 - mae: 4.5805\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.0187 - mae: 4.3083\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.8693 - mae: 4.5209\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 34.3096 - mae: 4.5367\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 30.4436 - mae: 4.2706\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 34.2223 - mae: 4.5137\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.5891 - mae: 4.3179\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 30.2037 - mae: 4.3487\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 35.0950 - mae: 4.5862\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.3326 - mae: 4.2047\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.7378 - mae: 4.6966\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.8505 - mae: 4.1413\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.5257 - mae: 4.3950\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 35.7796 - mae: 4.8325\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 29.4404 - mae: 4.3825\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.4674 - mae: 4.0270\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 29.7535 - mae: 4.0057\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.1536 - mae: 4.4067\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.3420 - mae: 4.0795\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 29.1741 - mae: 4.4050\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.5990 - mae: 4.8573\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 41.0216 - mae: 4.8674\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 30.7808 - mae: 4.5019\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.3938 - mae: 4.3963\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 30.4017 - mae: 4.2631\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 27.4749 - mae: 4.1764\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.4493 - mae: 3.8779\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 26.5801 - mae: 4.0563\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 27.7270 - mae: 3.9320\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.3697 - mae: 4.4909\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.6969 - mae: 4.3086\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.0303 - mae: 4.9256\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.3738 - mae: 5.3139\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.2935 - mae: 4.4633\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 34.0278 - mae: 4.5273\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 29.8136 - mae: 4.0735\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.2468 - mae: 4.3370\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.9083 - mae: 4.2134\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 47.6826 - mae: 5.5656\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 52.6566 - mae: 5.5151\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 44.7599 - mae: 5.1436\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 26.2754 - mae: 3.8751\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_test_function.<locals>.test_function at 0x7fb598986e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 27.1294 - mae: 3.5938\n",
            "Test accuracy: 3.5937540531158447\n",
            "Epoch 1/50\n",
            "110/110 [==============================] - 1s 1ms/step - loss: 13528.9600 - mae: 56.5629\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 182.3307 - mae: 8.8944\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 87.0371 - mae: 6.4063\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 64.4987 - mae: 5.6726\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 71.5148 - mae: 5.9921\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 55.4737 - mae: 5.2220\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 49.8634 - mae: 4.9599\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 52.9745 - mae: 5.1503\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 56.2597 - mae: 5.3996\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.9356 - mae: 5.6123\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 55.1673 - mae: 5.1946\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.2983 - mae: 5.9321\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 69.2282 - mae: 6.4358\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.7095 - mae: 4.9773\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 67.2913 - mae: 5.9334\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 50.3734 - mae: 5.2227\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 104.2426 - mae: 7.8386\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 42.0430 - mae: 4.7421\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 78.3472 - mae: 6.9161\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 55.3969 - mae: 5.8819\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 59.5732 - mae: 6.2413\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 73.3878 - mae: 6.8139\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 50.0156 - mae: 5.3008\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 55.1893 - mae: 6.0839\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 62.1691 - mae: 6.1178\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 56.0427 - mae: 5.9205\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 43.0244 - mae: 5.2100\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 49.8730 - mae: 5.4391\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 50.4901 - mae: 5.4923\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 80.8282 - mae: 6.7591\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.7459 - mae: 6.1304\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 81.4052 - mae: 7.0385\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 40.1819 - mae: 4.7901\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 45.5420 - mae: 5.2896\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 54.7046 - mae: 5.6142\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 52.0612 - mae: 5.3384\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 76.2332 - mae: 6.4251\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 60.0253 - mae: 5.9993\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 44.1962 - mae: 5.3656\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 55.0247 - mae: 5.9193\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 60.6413 - mae: 5.9879\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 99.6698 - mae: 7.5940\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 59.3168 - mae: 6.0410\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 86.0910 - mae: 6.9325\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.0173 - mae: 4.6845\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.5736 - mae: 4.5187\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 131.7913 - mae: 8.7017\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 60.6979 - mae: 5.9089\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 88.1588 - mae: 7.2911\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 90.8221 - mae: 7.3589\n",
            "1/1 [==============================] - 0s 103ms/step - loss: 30.5332 - mae: 3.9473\n",
            "Test accuracy: 3.9472949504852295\n",
            "Epoch 1/50\n",
            "110/110 [==============================] - 1s 1ms/step - loss: 215213.5156 - mae: 299.0917\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 266.7903 - mae: 12.9778\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 170.0169 - mae: 10.6769\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 158.4731 - mae: 10.2317\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 128.3023 - mae: 8.6104\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 107.8862 - mae: 8.5096\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 89.7156 - mae: 7.5566\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 84.5234 - mae: 7.5167\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 80.7656 - mae: 6.9485\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 73.1442 - mae: 6.4909\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 60.4963 - mae: 6.0472\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 62.7105 - mae: 6.3874\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 67.8586 - mae: 6.2907\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 63.1821 - mae: 6.0915\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 59.5571 - mae: 5.8999\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.1404 - mae: 5.8822\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 62.8665 - mae: 6.2647\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.0418 - mae: 6.0723\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 56.0827 - mae: 5.8405\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 55.3489 - mae: 5.9761\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 52.6303 - mae: 5.6526\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 49.8400 - mae: 5.4144\n",
            "Epoch 23/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 54.5708 - mae: 5.9890\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 48.9499 - mae: 5.7901\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 43.3691 - mae: 5.2345\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.1267 - mae: 4.9773\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.8571 - mae: 4.7514\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.1369 - mae: 5.4742\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 34.6717 - mae: 4.6237\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 38.0142 - mae: 5.0956\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.1303 - mae: 4.5855\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 30.8392 - mae: 4.4070\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 35.0731 - mae: 4.7840\n",
            "Epoch 34/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 44.3214 - mae: 5.2490\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 42.1330 - mae: 5.1188\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 35.2862 - mae: 4.5935\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.8856 - mae: 4.5910\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.3860 - mae: 4.1506\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.8482 - mae: 4.3748\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.6214 - mae: 4.6290\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 42.3214 - mae: 5.1774\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.1879 - mae: 4.2678\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.2245 - mae: 4.4805\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.0941 - mae: 4.0700\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 53.2180 - mae: 5.7720\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.1022 - mae: 4.3282\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 29.4469 - mae: 4.2621\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.6068 - mae: 4.9616\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 49.0614 - mae: 5.7579\n",
            "Epoch 50/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 31.4113 - mae: 4.4466\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 35.3250 - mae: 4.2566\n",
            "Test accuracy: 4.256577014923096\n",
            "Epoch 1/50\n",
            "110/110 [==============================] - 1s 1ms/step - loss: 1778.2014 - mae: 24.6912\n",
            "Epoch 2/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 129.2945 - mae: 8.6453\n",
            "Epoch 3/50\n",
            "110/110 [==============================] - 0s 2ms/step - loss: 97.4432 - mae: 8.4164\n",
            "Epoch 4/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 80.0961 - mae: 7.4421\n",
            "Epoch 5/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 62.0068 - mae: 6.2929\n",
            "Epoch 6/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 62.3200 - mae: 6.3427\n",
            "Epoch 7/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 69.4096 - mae: 6.5751\n",
            "Epoch 8/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 49.9123 - mae: 5.9223\n",
            "Epoch 9/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 51.5839 - mae: 5.9109\n",
            "Epoch 10/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 58.4961 - mae: 6.1999\n",
            "Epoch 11/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 51.5554 - mae: 5.6642\n",
            "Epoch 12/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 51.7255 - mae: 5.2954\n",
            "Epoch 13/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 59.7221 - mae: 6.1927\n",
            "Epoch 14/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 43.4951 - mae: 5.1097\n",
            "Epoch 15/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.8402 - mae: 4.6828\n",
            "Epoch 16/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 66.3319 - mae: 6.0885\n",
            "Epoch 17/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 33.0322 - mae: 4.4383\n",
            "Epoch 18/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 46.6583 - mae: 5.6831\n",
            "Epoch 19/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.4197 - mae: 4.4896\n",
            "Epoch 20/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.5176 - mae: 5.5086\n",
            "Epoch 21/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 41.8477 - mae: 5.1667\n",
            "Epoch 22/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 43.8686 - mae: 5.2201\n",
            "Epoch 23/50\n",
            "  1/110 [..............................] - ETA: 0s - loss: 1.8621 - mae: 1.3646"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7fb5b8c40170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n",
            "    handle=self._handle, deleter=self._deleter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n",
            "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 0s 1ms/step - loss: 37.1977 - mae: 5.0752\n",
            "Epoch 24/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 40.4394 - mae: 5.0074\n",
            "Epoch 25/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 56.2941 - mae: 5.5581\n",
            "Epoch 26/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 69.0051 - mae: 6.6303\n",
            "Epoch 27/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.8009 - mae: 4.8352\n",
            "Epoch 28/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 45.0104 - mae: 5.3416\n",
            "Epoch 29/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 67.7795 - mae: 6.0406\n",
            "Epoch 30/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 73.5785 - mae: 6.7916\n",
            "Epoch 31/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 49.5565 - mae: 5.5291\n",
            "Epoch 32/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.6184 - mae: 4.8870\n",
            "Epoch 33/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 40.4678 - mae: 4.8684\n",
            "Epoch 34/50\n",
            "  1/110 [..............................] - ETA: 0s - loss: 30.2524 - mae: 5.5002"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Exception ignored in: <function IteratorResourceDeleter.__del__ at 0x7fb5b8c40170>\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/data/ops/iterator_ops.py\", line 546, in __del__\n",
            "    handle=self._handle, deleter=self._deleter)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 1264, in delete_iterator\n",
            "    _ctx, \"DeleteIterator\", name, handle, deleter)\n",
            "KeyboardInterrupt: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "110/110 [==============================] - 0s 1ms/step - loss: 48.9001 - mae: 5.4866\n",
            "Epoch 35/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.2812 - mae: 4.9350\n",
            "Epoch 36/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.2030 - mae: 4.8705\n",
            "Epoch 37/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 56.9871 - mae: 5.3930\n",
            "Epoch 38/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 41.0623 - mae: 5.3101\n",
            "Epoch 39/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 26.0313 - mae: 3.7926\n",
            "Epoch 40/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 29.0291 - mae: 4.1996\n",
            "Epoch 41/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.8097 - mae: 4.4893\n",
            "Epoch 42/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 39.7839 - mae: 4.9256\n",
            "Epoch 43/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.8931 - mae: 4.4475\n",
            "Epoch 44/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.4645 - mae: 4.9375\n",
            "Epoch 45/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 34.9788 - mae: 4.6122\n",
            "Epoch 46/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 36.8481 - mae: 4.7319\n",
            "Epoch 47/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 32.5785 - mae: 4.4062\n",
            "Epoch 48/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 37.0776 - mae: 4.5091\n",
            "Epoch 49/50\n",
            "110/110 [==============================] - 0s 1ms/step - loss: 28.1000 - mae: 3.9804\n",
            "Epoch 50/50\n",
            "  1/110 [..............................] - ETA: 0s - loss: 0.5561 - mae: 0.7457"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-b60334d2ab25>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_compiled_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m   \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_average_points\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                 _r=1):\n\u001b[1;32m   1182\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   3023\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 3024\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   3025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1959\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1960\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1961\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1962\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1963\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    594\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    597\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdLB0FBxCRpg"
      },
      "source": [
        "model.save('Newest_Accurate_QB_Model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}